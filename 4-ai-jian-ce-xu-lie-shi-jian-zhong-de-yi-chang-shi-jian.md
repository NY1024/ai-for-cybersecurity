# 4 AI检测序列事件中的异常事件

## 4.1 安全问题

\
异常检测在各行各业被广泛考虑，以实现更高级别的安全性。异常检测寻找观察行为中的意外变化（即与正常情况的偏离）。当应用于入侵检测系统（IDS）时，如果识别到离群值，它会怀疑并预测攻击。

假设在特定时间间隔内监控网络活动，我们使用eᵢ表示第i个活动。让我们用E = {e₁, e₂, e₃, ..., eₙ}表示长时间内所有网络活动的集合。异常检测器将eᵢ视为一个事件，将{eᵢ, eᵢ₊₁, ..., eᵢ₊ⱼ}视为事件序列。

通常，异常检测有两个基本假设：a）在正常行为中，异常事件子序列很少存在；b）它们的特征与正常事件显著不同。因此，安全分析人员对数据集E进行异常检测，以识别与所有其他时间间隔相比异常的时间间隔（事件子序列）。

## 4.2 数据集

\
我们介绍两个数据集，分别是UNSW-NB15 \[56] 和 SOSP2009 \[87]。

### 4.2.1 UNSW-NB15数据集

\
澳大利亚网络安全中心（ACCS）的网络安全实验室于2015年发布了UNSW-NB15。该数据集包括真实正常活动和由IXIA PerfectStorm工具生成的合成网络攻击行为的混合。

首先，需要注意流是从源IP到目的地的数据包序列。数据集包含2,218,761个（87.35%）良性流和321,283个（12.65%）攻击流，总计2,540,044个流。具体而言，数据集包括九种类型的攻击，分别是Fuzzers、Analysis、Backdoors、DoS、Exploits、Generic、Reconnaissance、Shellcode和Worms，这些攻击是由Tcpdump工具捕获的。数据集中的数据包由Argus数据包处理器、Bro和其他十二个附加算法提供的49个不同特征进行描述。

最常用的训练集（UNSW\_NB15\_training-set.csv1），包含175,341个流，以及测试集（UNSW\_NB15\_testing-set.csv2），包含82,332个流，是整个数据集的一部分，并可供研究人员使用，以帮助他们开发基于数据的攻击检测技术。



### 4.2.2 SOSP 2009 Log数据集

表4.2提供了SOSP 2009日志数据集的简要概述，实际上是一个Hadoop文件系统（HDFS）控制台日志数据集。此日志集在私有云环境中使用基准工作负载生成。通过手工制定的规则，日志条目被手动标记以识别异常。具体而言，日志数据集包含来自在203个Amazon EC2节点上运行的Hadoop MapReduce操作的1100多万个日志条目，历时两天。每个日志条目都有一个块标识符（表示为块ID），每个HDFS块可以被视为一个独立的线程。

每个日志条目对应于一个独特的事件。所有事件都被分类为一组类别：每个类别由一个日志键ki表示。此外，每个会话被定义为发生在特定块ID上的一系列事件。（没有会话涉及两个或更多块ID。）由于没有块ID出现在两个或更多会话中，我们可以直接将块ID标记为正常或异常。如表4.2所示，标签（即正常或异常）是在会话级别提供的，有558,223个正常会话和16,838个异常会话。整个数据集包括一个正常训练集（4,855个解析的会话），一个正常测试集（553,366个解析的会话），一个异常训练集（1,638个解析的会话）和一个异常测试集（15,200个解析的会话）。



<figure><img src=".gitbook/assets/image (27).png" alt=""><figcaption></figcaption></figure>

## 4.3 数据处理



### 4.3.1 SOSP 2009 Log数据集

代码4.1是一个原始HDFS日志的示例，记录了“INFO”文本后的系统行为、源IP地址和目标IP地址。“blk\_-1608999687919862906”是一个块ID。表4.3展示了一些正常的块ID和一些异常的块ID。

<figure><img src=".gitbook/assets/image (29).png" alt=""><figcaption><p>代码4.1：HDFS日志数据集中的示例原始数据</p></figcaption></figure>

<figure><img src=".gitbook/assets/image (30).png" alt=""><figcaption></figcaption></figure>

\
在数据处理阶段，我们首先将日志键重新设计为三个键集K0（新基础）、K1和K2。它们分别包含31、101和304个日志键。由于会话和块ID都有标签，因此可以安全地使用日志键对每个事件（即日志条目）进行编码，而无需修改原始事件序列。在配置seqlen = 10下，每个键集的统计信息如表4.4所示。这些键集来自同一个日志，只是K1和K2通过重新附加附加字符串来丢弃较少的信息，例如：



<figure><img src=".gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

\
\
有三种附加字符串类型：

1. 对于涉及文件路径的两个日志键，我们附加32个文件路径附加字符串之一（例如/user/root/randtxt/temporary/task\*/part\*）。
2. 对于涉及文件大小的两个日志键，我们附加七个10 MB间隔附加字符串之一（例如0-10 MB）。
3. 对于涉及IP地址的事件，我们根据以下规则附加附加字符串：
   * 如果日志条目涉及源IP地址和目标IP地址，我们检查并附加表示它是否“在本地”内的附加字符串；如果不是，则通过IP前缀（例如10.251.7\*）检查它是否“在子网内”或“在子网之间”。
   * 如果日志条目涉及源IP地址或目标IP地址之一，我们附加表示方向和IP前缀的附加字符串（例如，从10.251.7\*）。

对于K1和K2，IP前缀的粒度不同：对于K1，它使用前两个小数（例如10.251._），而对于K2，它使用一个更多的小数（例如10.251.7_）。我们通过附加附加字符串来拆分K0，但我们还丢弃了没有发生的键。

代码4.2展示了数据处理的代码片段。



<figure><img src=".gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (3).png" alt=""><figcaption><p>代码4.2 SOSP2009数据处理</p></figcaption></figure>

### 4.3.2 UNSW-NB15数据集
